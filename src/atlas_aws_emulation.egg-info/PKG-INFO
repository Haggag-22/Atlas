Metadata-Version: 2.4
Name: atlas-aws-emulation
Version: 0.1.0
Summary: Advanced AWS Cloud Adversary Emulation framework for lab environments
Author: Atlas
License: MIT
Keywords: aws,security,adversary-emulation,mitre-attack
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Security
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: boto3>=1.28.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pydantic-settings>=2.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: pyyaml>=6.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: pytest-mock>=3.10.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"

# Atlas – AWS Cloud Adversary Emulation Framework

**Production-quality Python framework for AWS adversary emulation in lab environments.**  
Campaign-based execution aligned to MITRE ATT&CK, with a clean modular architecture, safety controls, telemetry, and a plugin system for techniques.

> **Lab use only.** Run only in AWS accounts you own or are authorized to test. You are responsible for compliance with AWS Terms of Service and your organization’s policies.

---

## Features

- **Campaign orchestrator** – Run ordered techniques as steps, with shared state (accounts, roles, resources, credentials refs, findings) and structured JSON timeline + human-readable report.
- **Plugin system** – Each technique is a module with a standard interface: `name`, `description`, `required_permissions`, `inputs`, `execute()`, `outputs`, `rollback()`; campaigns are YAML files referencing technique IDs and parameters.
- **Reconnaissance** – Scan local Git repos or given paths for leaked secrets and misconfig patterns (no internet scraping); normalize findings and optionally feed campaign inputs.
- **Telemetry** – Record every action (timestamp, actor, AWS API, resource ARN, region, result, error, evidence pointers) with optional CloudTrail enrichment.
- **Safety controls** – Hard allowlist of AWS account IDs and regions, mandatory confirmation for destructive actions, dry-run mode, rate limiting and jitter, and a clear lab-only banner.

## Built-in techniques (read-only / safe)

| Technique ID               | Description                              | MITRE        |
|---------------------------|------------------------------------------|-------------|
| `identity_discovery`      | Caller identity + IAM users              | T1078       |
| `permission_enumeration`   | User/role attached and inline policies   | T1069       |
| `role_trust_analysis`     | IAM role trust policies                  | T1098       |
| `s3_enumeration`           | S3 buckets + public access block         | T1530       |
| `security_group_enumeration` | EC2 security groups and rules         | T1565       |
| `iam_policy_simulation`   | SimulatePrincipalPolicy for actions      | T1069       |

---

## Project structure

```
src/atlas/
  cli/          # CLI entrypoint, config loading, rich output
  core/         # Config, state, plugin base, orchestrator, safety
  plugins/      # Registry + techniques (identity, permissions, roles, S3, SG, IAM sim)
  recon/        # Local path / repo scanner for secrets and misconfigs
  telemetry/    # Event schema and recorder
  utils/        # Rate limiting, jitter
campaigns/      # Example YAML campaigns
config/         # Example atlas config
examples/output/# Sample timeline and report
tests/          # Pytest tests
```

---

## Requirements

- Python 3.10+
- boto3, pydantic, pydantic-settings, rich, PyYAML

---

## Installation

```bash
# From repo root
pip install -e .

# Or with uv
uv pip install -e .
```

For development (tests, lint, pre-commit):

```bash
pip install -e ".[dev]"
pre-commit install
```

---

## Configuration

1. Copy the example config and restrict to your lab account/regions:

   ```bash
   cp config/atlas.example.yaml atlas.yaml
   ```

2. Edit `atlas.yaml`:

   ```yaml
   safety:
     allowed_account_ids:
       - "123456789012"
     allowed_regions:
       - "us-east-1"
       - "us-west-2"
     dry_run: false
     rate_limit_per_second: 5.0
     jitter_seconds: 0.5

   aws_profile: "default"   # or your lab profile
   aws_region: "us-east-1"
   ```

3. **AWS credentials** – Use a profile or env vars so that only the lab account is used:

   ```bash
   export AWS_PROFILE=my-lab-profile
   # or
   export AWS_ACCESS_KEY_ID=... AWS_SECRET_ACCESS_KEY=... AWS_DEFAULT_REGION=us-east-1
   ```

   Ensure the profile/credentials have permissions for the techniques you run (e.g. `iam:ListUsers`, `s3:ListAllMyBuckets`, etc.).

---

## Running locally

### List plugins and campaigns

```bash
atlas list-plugins
atlas list-campaigns --campaigns-dir campaigns
```

### Run a campaign (dry-run first)

```bash
# Dry run (no AWS calls)
atlas run campaigns/discovery.yaml --dry-run --output-dir output

# Real run
atlas run campaigns/discovery.yaml --output-dir output
```

Outputs are written under `output/<run_id>/`:

- `timeline.json` – Structured timeline (summary + events)
- `report.txt` – Human-readable summary and findings
- `state.json` – Final campaign state (accounts, roles, resources, findings)

### Recon (local paths only)

```bash
atlas recon .                          # current dir
atlas recon /path/to/repo /other/path
```

Findings are printed and optionally written to `recon_findings.json` for use as campaign inputs.

### Optional config path

```bash
atlas run --config atlas.yaml campaigns/discovery.yaml
atlas recon . --config atlas.yaml
```

### Environment overrides

- `ATLAS_AWS_PROFILE`, `ATLAS_AWS_REGION`
- `ATLAS_DRY_RUN=true`
- `ATLAS_ALLOWED_ACCOUNT_IDS=111,222`
- `ATLAS_ALLOWED_REGIONS=us-east-1,eu-west-1`

---

## End-to-end sample

1. Set lab account and region in `atlas.yaml` (or env).
2. Configure AWS (profile or env) for that account.
3. Dry run:

   ```bash
   atlas run campaigns/discovery.yaml --dry-run --output-dir output
   ```

4. Run for real:

   ```bash
   atlas run campaigns/discovery.yaml --output-dir output
   ```

5. Inspect `output/<run_id>/timeline.json` and `report.txt`.

---

## Adding techniques

1. Implement a class that subclasses `TechniquePlugin` in `src/atlas/core/plugin.py`:
   - `id`, `name`, `description`, `required_permissions`, `execute(state, parameters, config)`.
   - Return a `TechniqueResult` with `outputs`, `findings`, `resources` as needed.
2. Register it:

   ```python
   from atlas.plugins.registry import register_plugin
   register_plugin(MyPlugin())
   ```

3. Add a step in a campaign YAML:

   ```yaml
   steps:
     - technique_id: my_plugin_id
       parameters: {}
   ```

Use `atlas.plugins.base_aws` for session, safety checks, telemetry, and rate limiting.

---

## Tests and lint

```bash
pytest tests -v
pytest tests --cov=src/atlas --cov-report=term-missing

ruff check src tests && ruff format --check src tests
make test
make lint
```

---

## License

MIT. Use only in authorized lab environments.
